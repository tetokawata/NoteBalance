[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "格差/因果/比較分析のためのデータ分析 (ver 0.2.1)",
    "section": "",
    "text": "Preface\n定量的な比較分析の方法を、Rでの実装とともに紹介します。\n比較分析は、社会における「グループ間の違い」を明らかにすることを目標とします。 本ノートでは、データ上のある変数 \\(D\\) 間での、別の変数 \\(Y\\) の平均値の差を推定する方法を紹介します。 例えば性別 \\((D)\\) 間での賃金 \\((Y)\\) の平均格差を推定します。\n比較分析は、社会/市場を理解するための方法として、中核的な位置を占めています。 通常、これらの研究関心となる\\(D\\)については、\\(Y\\)以外の違いがあることが一般的です。 研究課題に応じて、これらの違いの一部を、データ分析上の処理として「解消(バランス)」することが必要です。\n例えば、性別\\((D)\\)間で見られる職業経験の違い\\(X\\)をバランスさせることで、職業経験以外の要因によって生じる男女間の賃金\\((Y)\\)格差が推定できます (Vafa, Athey, and Blei 2024)。 あるいは、ある職業訓練プログラム \\((D)\\) が就業確率や就業後の賃金 \\((Y)\\)に与える因果的効果を推定を試みます。 このような研究課題では、異なる職業訓練プログラムへの参加者間で、背景属性をバランスさせた上での、就業状態や賃金の比較が求められます (Behaghel, Crépon, and Gurgand 2014; Kallus 2023)。\n比較分析を行う上での、本ノートの中心的なコンセプトは、Balancing Weightです。 Balancing Weightは、以下のアプローチを統合的に整理できる極めて有益な概念です。\n\n重回帰(OLS)やPenalized Regressionによる調整(Chattopadhyay and Zubizarreta 2023; Bruns-Smith et al. 2023)\n傾向スコア(Propensity Score)の活用 (Imai and Ratkovic 2014)\n機械学習などを用いたDebiased Machine Learning (Chernozhukov et al. 2018; Chernozhukov, Escanciano, et al. 2022)\nEntropy Weight (Hainmueller 2012) やStable Weight (Zubizarreta 2015)、 Energy Weight (Huling and Mak 2024) による調整\n機械学習などを用いたAuto Debiased Machine Learning/Augmented Balancing Weights (Chernozhukov, Newey, and Singh 2022a, 2022b; Chernozhukov, Newey, et al. 2022; Bruns-Smith et al. 2023)\n\n簡易な入門としては Chattopadhyay and Zubizarreta (2024) 、詳細な入門としては Chattopadhyay, Hase, and Zubizarreta (2020) , Ben-Michael et al. (2021) などを参考にしてください。\n本ノートの構成は以下のとおりです。\n\n1  バランス後の比較 : 本ノートのEstimandである「バランス後の比較」を定義します。\n2  Weight : 本ノートの中核概念であるBalancing Weightを紹介する準備として、荷重(Weight)を定義します。\n3  Balancing Weight : Balancing Weightを定義します。またBalancing Weightの直感的な算出方法が、利用できない状況が多いことを指摘します。\n4  OLSによる特徴のバランス : より幅広い状況で算出できる近似的なBalancing Weightを紹介します。また標準的なOLS推定が、暗黙のうちに近似的なBalancing Weightを算出した、バランス後の比較と解釈できることを示します。\n5  直接的なBalancing Weightの算出 : 近似的なBalancing Weightを、明示的な最適化問題として算出する方法を紹介します。 代表的な方法の一つであるEntropy weight (Hainmueller 2012) は、その計算効率や分析の透明性の高さから、幅広く用いられています。\n6  機械学習の活用: 残差回帰 : 機械学習を用いた、よりデータ主導のアプローチを紹介します。残差回帰に機械学習を補助的に用いることで、近似的なBalancing Weightを算出した、バランス後の比較を行うことができます。OLSとは異なり、事例数が十分大きければ、「母集団上で、完全なBalanceを達成した後の比較分析」、の優れた推定値と見做せることを紹介します。\n7  機械学習の活用: AIPW : 機械学習を用いたBalanced comparisonの代替的な方法である、Augmented inverse probability weighting への活用を紹介します。残差回帰よりもEstimandの解釈が容易な一方で、\\(X\\)の分断が激しいケースでは推定結果が不安定になりやすいという問題点があります。\n\n\n\n\n\nBehaghel, Luc, Bruno Crépon, and Marc Gurgand. 2014. “Private and Public Provision of Counseling to Job Seekers: Evidence from a Large Controlled Experiment.” American Economic Journal: Applied Economics 6 (4): 142–74.\n\n\nBen-Michael, Eli, Avi Feller, David A Hirshberg, and José R Zubizarreta. 2021. “The Balancing Act in Causal Inference.” arXiv Preprint arXiv:2110.14831.\n\n\nBruns-Smith, David, Oliver Dukes, Avi Feller, and Elizabeth L Ogburn. 2023. “Augmented Balancing Weights as Linear Regression.” arXiv Preprint arXiv:2304.14545.\n\n\nChattopadhyay, Ambarish, Christopher H Hase, and José R Zubizarreta. 2020. “Balancing Vs Modeling Approaches to Weighting in Practice.” Statistics in Medicine 39 (24): 3227–54.\n\n\nChattopadhyay, Ambarish, and José R Zubizarreta. 2023. “On the Implied Weights of Linear Regression for Causal Inference.” Biometrika 110 (3): 615–29.\n\n\nChattopadhyay, Ambarish, and José R. Zubizarreta. 2024. Harvard Data Science Review 6 (1).\n\n\nChernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. “Double/Debiased Machine Learning for Treatment and Structural Parameters.” The Econometrics Journal 21 (1): C1–68.\n\n\nChernozhukov, Victor, Juan Carlos Escanciano, Hidehiko Ichimura, Whitney K Newey, and James M Robins. 2022. “Locally Robust Semiparametric Estimation.” Econometrica 90 (4): 1501–35.\n\n\nChernozhukov, Victor, Whitney K Newey, and Rahul Singh. 2022a. “Automatic Debiased Machine Learning of Causal and Structural Effects.” Econometrica 90 (3): 967–1027.\n\n\n———. 2022b. “Debiased Machine Learning of Global and Local Parameters Using Regularized Riesz Representers.” The Econometrics Journal 25 (3): 576–601.\n\n\nChernozhukov, Victor, Whitney Newey, Vıctor M Quintas-Martınez, and Vasilis Syrgkanis. 2022. “Riesznet and Forestriesz: Automatic Debiased Machine Learning with Neural Nets and Random Forests.” In International Conference on Machine Learning, 3901–14. PMLR.\n\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies.” Political Analysis 20 (1): 25–46.\n\n\nHuling, Jared D, and Simon Mak. 2024. “Energy Balancing of Covariate Distributions.” Journal of Causal Inference 12 (1): 20220029.\n\n\nImai, Kosuke, and Marc Ratkovic. 2014. “Covariate Balancing Propensity Score.” Journal of the Royal Statistical Society Series B: Statistical Methodology 76 (1): 243–63.\n\n\nKallus, Nathan. 2023. “Treatment Effect Risk: Bounds and Inference.” Management Science 69 (8): 4579–90.\n\n\nVafa, Keyon, Susan Athey, and David M Blei. 2024. “Estimating Wage Disparities Using Foundation Models.” arXiv Preprint arXiv:2409.09894.\n\n\nZubizarreta, José R. 2015. “Stable Weights That Balance Covariates for Estimation with Incomplete Outcome Data.” Journal of the American Statistical Association 110 (511): 910–22.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01Intro.html",
    "href": "01Intro.html",
    "title": "1  バランス後の比較",
    "section": "",
    "text": "1.1 不動産市場の年次比較\n典型的なバランス後の比較 (Balanced Comparison)分析 では、グループ\\(D\\)の間で、\\(X\\)についての差を解消した後に、\\(Y\\)についての平均差を推定します 1。 このような比較は、格差分析や因果効果の肝となります。\nまず実例から紹介します。\n東京23区の中古マンション市場において、2022年と2021年の取引価格と立地(中心6区(港区、中央区、文京区、千代田区、渋谷区、新宿区)、かそれ以外か)について、平均的な差を図示します。\n2022年の平均取引価格は、2021年に比べて上昇しており、不動産市場における価格上昇が続いているように見えます。 しかしながら、同時に中心6区の物件割合も増加しています。 一般に中心6区に立地する物件の方が、高い取引価格が予想されます。 このため物件の立地の変化によって、取引価格の上昇が”底上げ”されている可能性があります。\nもし中心6区の物件割合が不変であった場合、平均取引価格にどのような差が残るでしょうか？ このような問いに対して、バランス後の比較分析は回答できます。\n以下では実際のデータを用いて、取引年と立地(中心6区 であれば1、それ以外であれば0)ごとに、平均取引価格を示しています。 また各取引年における取引事例の立地割合も算出しています。\nExample\n\n\n平均価格(100万円)\n中心6区\n取引年\n事例割合\n\n\n\n\n37.748\n0\n2021\n0.784\n\n\n60.474\n1\n2021\n0.216\n\n\n39.150\n0\n2022\n0.779\n\n\n64.814\n1\n2022\n0.221\n繰り返し期待値の法則を用いると2022年と2021年の平均取引価格の差を算出できます。\nExampleに適用すると、2022年の平均取引価格は以下のように計算できます。\n\\[2022年の平均価格\\]\n\\[= \\underbrace{64.814}_{中心6区における平均価格}\\times\\underbrace{0.221}_{中心6区に立地する事例の割合}\\] \\[+ \\underbrace{39.150}_{中心6区以外における平均価格}\\times \\underbrace{0.779}_{中心6区以外に立地する事例の割合}\\]\n\\[=44.810\\]\n2021年の平均取引価格も同様に計算できます。\n\\[2021年の平均価格 = 60.474\\times0.216 + 37.748\\times 0.784=42.658\\]\n2022年と2021の平均差を計算すると、2022年の平均取引価格の方が、2.153ほど高くなっていることが確認できます。\n繰り返し期待値の法則自体は、シンプルな計算ルールですが、「\\(X\\)のバランス」の意義を明確にします。 繰り返し期待値の法則から、平均価格の違いは、同じ立地内での平均取引価格の違いと立地の割合の違いによって生じることがわかります。 2021年と比べると、2022年に取引された物件の中で、中心6区の物件割合が21.6 \\(\\%\\) から 22.1 \\(\\%\\) に上昇しています。 一般に中心6区の方が、物件の価格が高い傾向にあります。 このため、中心6区の物件割合の違いが、平均取引価格上昇の一因となっている可能性があります。\nバランス後の比較分析では、「取引されている物件に占める中心6区の割合が、変化しなかった場合」の 平均取引価格の変化を推定します。 より一般的には、「\\(X\\)についての差を解消した状態で」\\(D\\)間で\\(Y\\)を比較します。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>バランス後の比較</span>"
    ]
  },
  {
    "objectID": "01Intro.html#不動産市場の年次比較",
    "href": "01Intro.html#不動産市場の年次比較",
    "title": "1  バランス後の比較",
    "section": "",
    "text": "繰り返し期待値の法則\n\n\n\n\n変数\\(Y,D\\)と他の変数\\(X\\)について、\\(Yの平均値\\)は以下のように書き換えられる。\n\n\\[(D=d)におけるYの平均値\\]\n\\[=(D=d,X=x_1)を満たす事例のYの平均値\\] \\[\\times (D=d,X=x_1)を満たす事例の割合\\]\n\\[+..\\]\n\\[+(D=d,X=x_L)を満たす事例のYの平均値\\] \\[\\times (D=d,X=x_L)を満たす事例の割合\\]\n\nただし \\(X\\)がとりえる値は、\\(x_1,..,x_L\\) とする。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>バランス後の比較</span>"
    ]
  },
  {
    "objectID": "01Intro.html#バランス後の平均差",
    "href": "01Intro.html#バランス後の平均差",
    "title": "1  バランス後の比較",
    "section": "1.2 バランス後の平均差",
    "text": "1.2 バランス後の平均差\n本ノートにおいて、バランス後の比較分析の一つである「バランス後の平均差」を推定します。\n\n\n\n\n\n\nバランス後の平均値\n\n\n\n\\[(D=d)におけるYの平均値\\]\n\\[=(D=d,X=x_1)を満たす事例のYの平均値\\] \\[\\times (X=x_1)についてのターゲットとなる割合\\]\n\\[+..\\]\n\\[+(D=d,X=x_L)を満たす事例のYの平均値\\] \\[\\times (X=x_L)についてのターゲットとなる割合\\]\n\nターゲットとなる割合は、\\(D\\)の値にかかわらず同じ値として、研究者が定める。\n\n\n\nバランス後の平均値の計算例として、以下ではターゲットを取引年にかかわらず、「中心6区が0.25, その他が0.75」と設定し、Exampleに適用します。\n\n\n\n\n\n\n\n\n平均価格\n中心6区\n取引年\n事例割合\nターゲットとなる割合\n\n\n\n\n37.748\n0\n2021\n0.784\n0.750\n\n\n60.474\n1\n2021\n0.216\n0.250\n\n\n39.150\n0\n2022\n0.779\n0.750\n\n\n64.814\n1\n2022\n0.221\n0.250\n\n\n\n\n\n\n\nターゲットのもとでは、取引年にかかわらず、中心6区とそれ以外に立地する事例の割合は一定となります。 このため平均価格の変化を生み出す要因から、事例割合の変化を排除できます。\n事例割合をターゲットに差し替えて、繰り返し期待値の法則を適用すると、バランス後の平均価格は以下のように計算できます。\n\\[2022年のバランス後の平均価格\\]\n\\[= 64.814\\times\\underbrace{0.25}_{中心6区についてのターゲット}\\] \\[+ 39.150\\times \\underbrace{0.75}_{中心6区以外についてのターゲット}=45.566\\]\n\\[2021年のバランス後の平均価格 = 60.474\\times0.25 + 37.748\\times 0.75=43.4295\\]\nバランス後の平均差は、2.1365であり、バランス前(2.153)に比べて縮小しました。\n\n1.2.1 Overlapの仮定\nバランス後の平均差が計算できる前提条件は、Overlapの仮定 (Positivityの仮定とも呼ばれます) が成り立っていることです。\n\n\n\n\n\n\nImportant 1.1: Overlapの仮定\n\n\n\n\nターゲットとなる割合が0よりも大きい\\(X\\)の組み合わせについて、\\(D=1\\)の事例も\\(D=0\\)の事例も、両方存在する: \\[1 &gt; \\Pr[D=d|X] &gt;0\\] ただし \\(\\Pr[D=d|X]\\) は\\((X=x)\\)内での\\(D=d\\)の割合(\\(D=1\\)の割合)\n\n\n\nOverlapが成り立っていない場合、全ての\\(D\\)について平均値が計算できず、厳密なバランス後の比較は根本的に不可能です。\n例えば、教育経験\\((=X)\\)をバランスさせた男女間\\((=D)\\)での賃金格差を推定したいとします。 もしデータにおける男女間での教育経験の分断が極めて大きい場合、大学卒以上の女性は存在しない可能性があります。 この場合、\\(X=大学卒\\)の女性割合は\\(0\\)であり、大学卒内で男女間比較は不可能です。 このため大学卒について、ターゲットとなる割合を”0”としない限り、バランス後の比較は不可能です。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>バランス後の比較</span>"
    ]
  },
  {
    "objectID": "01Intro.html#応用事例",
    "href": "01Intro.html#応用事例",
    "title": "1  バランス後の比較",
    "section": "1.3 応用事例",
    "text": "1.3 応用事例\nバランス後の比較分析の応用例は、大量に存在します。 以下では実務においてよく利用されている指標を紹介します。\n\n1.3.1 既存店ベースの比較\nバランス後の比較は、企業の経営戦略を考える上でも用いられます。\n小売や飲食/宿泊業などでは、しばしば既存店に絞った上での、売上比較がなされます。 例えば、あるコンビニチェーンで、店舗あたりの平均売り上げが1000万円増大したとします。 同時に去年から今年にかけて、新規出店も大きく増加したとします。 新規店の方が売上が高くなる傾向がある場合、新規店割合の違いが、平均売上の上昇をもたらした可能性があります。\n既存店割合をバランスさせるシンプルな方法として、既存店のみに絞った平均売上を比較がよく行われます。 このような分析では、既存店比率は全ての年について\\(100 \\%\\)となり、完全なバランスが達成されます。\n既存店ベースの比較におけるターゲット割合は、新規店については1、新規店以外については0となります。\n\n\n1.3.2 合計特殊出生率の時点/地域間比較\nバランス後の比較分析は、社会/政策分析においても幅広く利用されています。 代表例は、合計特殊出生率の国家間/時代間比較です。\n出生数の動向を把握する上で、新生児数を年次や国家間比較は、有益だとみなされてきました。 合計特殊出生率 は、成人の年齢構造の違いをバランスさせるために利用されている指標です。 単純な出生率（一年間に生まれた子供の数/女性の数）は、成人の年齢構造の影響を強く受ける可能性があります。 社会において高齢者の比率が高まれば、出生率は低下することが予想されるからです。 対して合計特殊出生率は、「仮に年齢構造が同じであった場合」の出生率を、以下の方法で推定しています \\[\\frac{15歳の女性が産んだ子供の数}{15歳の女性の数} +..+ \\frac{49歳の女性が産んだ子供の数}{49歳の女性の数}\\]\n合計特殊出生率の計算においては、15歳から49歳の女性の年齢 (\\(=X\\))層が同じ割合になることを目指しています。 すなわちターゲット割合は、15歳から49歳までについて 1/34、それ以外の層については”0”となります。\n\n\n1.3.3 物価指数\nより複雑な比較が要求される指標の代表例は、物価指数です。 物価指数は、“同じような消費生活”を送るために必要な支出額を、比較するために算出されます (wiki)。 この際に問題となるのは、実際に消費する商品の組み合わせや量は、年毎に変化することです。 すなわち \\(D=\\) 時点、\\(Y=\\) 名目価格、\\(X=\\) “品目”とし、消費する”品目”をバランスさせる必要があります。\nBajari et al. (2023) は、機械学習の手法と商品の画像やテキストデータも用いることで、”質”も含めてバランスする試みを行なっています。 このような分析によって、“ステレス値上げ”や”商品の質的改善”にも対応できる指標が作成できる可能性があります。\n\n\n1.3.4 因果効果\nバランス後の比較は、因果効果を推定する際にも、中心的な役割を果たします。 因果効果を記述する枠組みは、多数提案されています (Pontial outcome/Structural Equation Model (DAG)/ 経済モデルなど)。 これらは共通して、思考実験、(特に反実仮想実験)の重要性を指摘しています。\nここでは反実仮想を明らかにできる仮想的な実験 (Target trial) を想像します。 典型的には、「無限大の被験者を用意し、被験者間の相互作用がない環境で、ランダムに選ばれた一部の被験者に介入を行う」実験です。 このような実験結果をもし得ることができれば、介入を行った/行わなかった被験者を比較することで、介入の因果効果を明らかにできます。 介入は完全ランダムに決まっているため、介入を行った/行わなかった集団間で、背景属性について大きな差が生じないことを担保できます2。\n現実に、このような大規模な実験を行うことは不可能です。 このため現実のデータから、理想的な実験結果を可能な限り再現することを目指します。\nEgami et al. (2024) は、TVゲームが精神的健康状態に与える因果効果について、実証的な証拠を提供しています。 同論文では、コロナ下で生じたゲーム機への過大需要と、それに対応するために実施された「ゲーム機購入権くじ」を利用しています。 同時期においては、ゲーム機購入希望者の中で、くじに当選した人だけゲームを購入することができました。 このため理想的な実験に近い状況が生じています。\nしかしながら、理想的な実験とは異なり、背景属性に幾つかの違いが生じる可能性があります。 例えば地域によってくじの当選確率が異なるのであれば、ゲーム機購入者と非購入者の間で、居住地に偏りが生じてしまいます。\n以上に対応するために、\\(D=\\) くじに当選、\\(Y=\\) 健康状態、 \\(X=\\) 居住地等とし、当選/非当選者間で背景属性をバランスさせた推定を行なっています。\n\n\n1.3.5 格差分析\n格差分析においても、バランス後の比較は重要です。 格差分析の出発点は、通常格差/差別/不平等の大きさの推定です。 このためには、研究対象とする格差を明確に定義する必要があります。\n因果効果と同様に、格差の定義についても、多様な議論があります (ヒュームの法則; Jackson and VanderWeele (2018); Rose (2023); Mossé et al. (2025) )。 代表的なものとして、格差や差別を因果的に定義するのは難しく、あくまで規範的に定義する立場があります。 すなわち「本来であれば存在すべきではない差」を格差として定義します。\n例えば、両親の教育経験間での、子供の所得格差に関心があるとします。 両親の属性に基づく差は、機会の不平等の代表的な例であり、多くの研究が行われてきました。\n実証上の論点は、両親の教育経験が異なれば、子供の年齢の分布も異なる可能性への対処です。 日本のような教育年数が急激に伸びた国においては、教育年数の長い両親の子供は、年齢が若い可能性があります。 また年功的賃金体系が残存していることを踏まえれば、年齢が若ければ賃金が低い傾向があります。 このため単純比較を行い、「教育年数の長い両親の子供の方が、短い両親の子供よりも所得が低い」、という結果を得たとしても、この差は年齢分布の違いを反映している可能性があります。\nもし研究関心が、「同じ世代なのに両親の教育経験によって生じる格差」にあるのであれば、子供の生まれ年を\\(X\\)としてバランスする必要があります。\nまたバランスは格差の要因分析にも応用できます。 このような分析は、分解分析 (Decomposition analysis)と呼ばれます (Opacic, Wei, and Zhou 2025)。 Vafa, Athey, and Blei (2024) では、男女間賃金格差の要因分析として、\\(X=\\) 職歴、\\(D=\\) 性別、\\(Y=\\) 賃金、とするバランス後の比較を行なっています。 職歴のバランス後にも、賃金格差が残存しているのであれば、採用時や個別賃金交渉における男女間での異なる取り扱いが男女間格差の要因であると解釈できます。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>バランス後の比較</span>"
    ]
  },
  {
    "objectID": "01Intro.html#応用上の課題",
    "href": "01Intro.html#応用上の課題",
    "title": "1  バランス後の比較",
    "section": "1.4 応用上の課題",
    "text": "1.4 応用上の課題\nバランス後の比較は、シンプルな枠組みです。 上記の例の通り、大規模なデータを用いて、少ない\\(X\\)をバランスさせるのであれば、単純な計算でバランスできます。\nしかしながら、多くの応用では複数の\\(X\\)を同時にバランスさせることが求められます。 このような応用では、同じ属性を持つ事例数が少なくなり、実際の計算は困難になります。\n多くの応用で活用できる、より実践的な推定方法が求められます。 このような推定手法は、Balancing Weight (Chapter 3) を実質的に推定していると解釈できます。 Chapter 2 ではBalancing Weightを理解するための準備として、一般的なWeightを紹介します。\n\n\n\n\nBajari, Patrick, Zhihao Cen, Victor Chernozhukov, Manoj Manukonda, Suhas Vijaykumar, Jin Wang, Ramon Huerta, et al. 2023. “Hedonic Prices and Quality Adjusted Price Indices Powered by AI.” arXiv Preprint arXiv:2305.00044.\n\n\nEgami, Hiroyuki, Md Shafiur Rahman, Tsuyoshi Yamamoto, Chihiro Egami, and Takahisa Wakabayashi. 2024. “Causal Effect of Video Gaming on Mental Well-Being in Japan 2020–2022.” Nature Human Behaviour 8 (10): 1943–56.\n\n\nGelman, Andrew, Jessica Hullman, and Lauren Kennedy. 2024. “Causal Quartets: Different Ways to Attain the Same Average Treatment Effect.” The American Statistician 78 (3): 267–72.\n\n\nJackson, John W, and Tyler J VanderWeele. 2018. “Decomposition Analysis to Identify Intervention Targets for Reducing Disparities.” Epidemiology (Cambridge, Mass.) 29 (6): 825.\n\n\nMossé, Milan, Kara Schechtman, Frederick Eberhardt, and Thomas Icard. 2025. “Modeling Discrimination with Causal Abstraction.” arXiv Preprint arXiv:2501.08429.\n\n\nOpacic, Aleksei, Lai Wei, and Xiang Zhou. 2025. “Disparity Analysis: A Tale of Two Approaches.” Journal of the Royal Statistical Society Series A: Statistics in Society, qnaf008.\n\n\nRose, Evan K. 2023. “A Constructivist Perspective on Empirical Discrimination Research.” Journal of Economic Literature 61 (3): 906–23.\n\n\nVafa, Keyon, Susan Athey, and David M Blei. 2024. “Estimating Wage Disparities Using Foundation Models.” arXiv Preprint arXiv:2409.09894.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>バランス後の比較</span>"
    ]
  },
  {
    "objectID": "01Intro.html#footnotes",
    "href": "01Intro.html#footnotes",
    "title": "1  バランス後の比較",
    "section": "",
    "text": "Gelman, Hullman, and Kennedy (2024)↩︎\n完全ランダムかつ無限大の被験者が存在すれば、格差は完全に消失します。現実の被験者数のもとでは、背景属性について偏りは生じますが、信頼区間などの統計的な手法でその影響を評価できます。↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>バランス後の比較</span>"
    ]
  },
  {
    "objectID": "02Weight.html",
    "href": "02Weight.html",
    "title": "2  Weight",
    "section": "",
    "text": "2.1 データ上の平均値\nBalancing Weightsを導入する準備として、より一般的な概念であるWeightsを紹介します。 Weightsは、データ上の事例の分布を、統計的な処理によって、変化させるために用いられます。\n以下、サンプリングの偏りへの対応を例とします。 前章のバランス後の比較分析と議論の多くが類似している点に注意してください。\n今、ある「不動産研究所」が調査員を千代田区、文京区、板橋区に派遣し、中古マンションの取引事例を収集したとします。 各調査員は、全く同じ数の事例を収集します。\n以下では、立地(District)ごとに、平均取引価格とデータ全体に対する事例の割合をまとめています。 全ての区について、同数の事例が収集されていることに注意してください。\nExample\n\n\n事例の割合\n平均価格\nDistrict\n\n\n\n\n0.333\n66.5\n千代田区\n\n\n0.333\n47.3\n文京区\n\n\n0.333\n29.5\n板橋区\n繰り返し期待値の法則を用いると、この情報のみからデータ全体の平均取引価格は計算できます。\n\\[=\\underbrace{66.5}_{千代田区の事例の平均取引価格}\\times \\underbrace{0.333}_{千代田区の事例の割合}\\]\n\\[+\\underbrace{47.3}_{文京区の事例の平均取引価格}\\times \\underbrace{0.333}_{文京区の事例の割合}\\]\n\\[+\\underbrace{29.5}_{板橋区の事例の平均取引価格}\\times \\underbrace{0.333}_{板橋区の事例の割合}\\]\n\\[=47.8\\]\n繰り返し期待値の法則から、データ上の平均値は、\\(X\\)についてのサブグループ内での平均値とサブグループの割合の掛け算の総和となります。 このため、もしサブグループの割合が研究関心から乖離している場合、サブグループ内での平均値が妥当な値であったとしても、ミスリードな平均値が計算されてしまいます。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Weight</span>"
    ]
  },
  {
    "objectID": "02Weight.html#データ上の平均値",
    "href": "02Weight.html#データ上の平均値",
    "title": "2  Weight",
    "section": "",
    "text": "\\(平均取引価格\\)は",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Weight</span>"
    ]
  },
  {
    "objectID": "02Weight.html#ターゲット上の平均値",
    "href": "02Weight.html#ターゲット上の平均値",
    "title": "2  Weight",
    "section": "2.2 ターゲット上の平均値",
    "text": "2.2 ターゲット上の平均値\n今研究関心は、「もし実際の取引履歴をすべて収集したデータを用いて計算された平均取引価格」、であるとします。 このような平均値を計算したい仮想的な割合を、バランス後の比較分析と同様に、ターゲット割合と呼びます。\n今、ターゲット割合は、千代田区が0.161、文京区が0.33、板橋区が0.509であることが判明しているとします。 もしデータ上の各区の取引割合を、ターゲットの取引割合と一致させた場合、平均値はどのように変化するでしょうか？\nExampleにおける調整された平均取引価格は、以下のように算出されます。\n\\[=\\underbrace{66.5}_{千代田区の事例の平均取引価格}\\times \\underbrace{0.161}_{千代田区の事例の割合}\\]\n\\[+\\underbrace{47.3}_{文京区の事例の平均取引価格}\\times \\underbrace{0.33}_{文京区の事例の割合}\\]\n\\[+\\underbrace{29.5}_{板橋区の事例の平均取引価格}\\times \\underbrace{0.509}_{板橋区の事例の割合}\\]\n\\[=41.3\\]\nデータ上の平均値は47.8であったので、過大であったことがわかります。 これは、平均取引価格が高い傾向にある千代田区の物件割合が、現実の取引割合(0.161)よりも、データ上の割合(0.333)が過大であることに起因します。\n\n2.2.1 バランス後の平均との類似性\n以上の議論は、バランス後の平均値と本質的には同じものです。 ターゲットとデータ上の分布が乖離しているため、平均値と調整された平均値は乖離しています。 唯一の違いは、バランス後の平均値を定義する際には、ターゲットを\\(D\\)の値に依存しないように設定する必要があり、Overlapの仮定 Important 1.1 に注意する必要がある点のみです。\nこのため以下の加重平均を用いた調整された平均値の計算方法は、バランス後の平均値を求める際にも利用できます。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Weight</span>"
    ]
  },
  {
    "objectID": "02Weight.html#加重平均値",
    "href": "02Weight.html#加重平均値",
    "title": "2  Weight",
    "section": "2.3 加重平均値",
    "text": "2.3 加重平均値\nターゲット割合へのバランスを行うための有力な方法は、加重平均(Weighted mean)を計算することです。 一般に加重平均は以下のように定義されます。\n\n\n\n\n\n\n加重平均値\n\n\n\n\n調整された平均値\n\n\\[=(\\underbrace{\\omega}_{Weight}\\times Y)の平均値\\]\n\nWeightに対して、\\(\\omega の平均値 = 1\\) を制約とする。\n\n\n\nWeightは各事例の\\(Y\\)の値が、最終的な平均値に反映される度合いをコントロールします。 例えば、もし\\(\\omega=0\\)であれば、その事例は平均値の計算に一切反映されません。\nWeightは、データとターゲットにおける\\(X\\)の分布を揃えるように設定されます。 すなわち\n\\[\\omega\\times データ上のXの割合=ターゲットとなるXの割合\\]\nを達成するように\\(\\omega\\)を算出します。 両辺を事例割合で割ると、\n\\[\\omega=\\frac{ターゲットとなる割合}{データ上の割合}\\] となります。 すなわちターゲットよりも過大に収集されているグループは小さめに、ターゲットよりも過小なグループは大きめに反映させます。\nExampleに適用すると、以下となります。\n\n\n\n\n\n\n\n\n平均価格\nDistrict\nターゲットとなる割合\n事例の割合\nWeight\n\n\n\n\n66.5\n千代田区\n0.161\n0.333\n0.483\n\n\n47.3\n文京区\n0.330\n0.333\n0.991\n\n\n29.5\n板橋区\n0.509\n0.333\n1.529\n\n\n\n\n\n\n\n加重平均値は以下のように算出できます。\n\\[\\Biggr[\\underbrace{\\underbrace{44}_{取引価格}\\times \\underbrace{0.483}_{荷重} + 70.0\\times 0.483+..}_{千代田区の事例}\\underbrace{+75.0\\times 0.991+..}_{文京区の事例}\\]\n\\[\\underbrace{+59.0\\times 1.529+..}_{板橋区の事例}\\Biggr]の平均=\\underbrace{41.3}_{調整された平均値}\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Weight</span>"
    ]
  },
  {
    "objectID": "03BalanceWeight.html",
    "href": "03BalanceWeight.html",
    "title": "3  Balancing Weight",
    "section": "",
    "text": "3.1 Balancing Weightの定義\n\\(D\\)間での\\(X\\)の分布をバランスを達成する実用的な手法は、数多く提案されています (Chattopadhyay, Hase, and Zubizarreta 2020; Bruns-Smith et al. 2023)。 このような手法を整理し、活用していくためには、Balancing weight という概念を導入することが有益です。\nBalancing weightは、前章で導入したWeightの一種であり、\\(D\\)間での\\(X\\)の分布の乖離を調整するために用いられます。\nターゲットは、原理的には研究者が指定する必要があります。 代表的なものは、データ全体における\\(X\\)の分布です1。\n先のデータに適用すると、以下のようなBalancing Weightが計算されます。\n平均価格\n中心6区\n取引年\n事例割合\nターゲット割合\nWeight\n\n\n\n\n37.748\n0\n2021\n0.784\n0.782\n0.997\n\n\n60.474\n1\n2021\n0.216\n0.218\n1.010\n\n\n39.150\n0\n2022\n0.779\n0.782\n1.003\n\n\n64.814\n1\n2022\n0.221\n0.218\n0.989\n2022年と2021年を結合したデータ全体のうち、中心6区に立地する物件割合は\\(21.8\\%\\) 、それ以外が \\(78.2\\%\\) であったので、ターゲットして設定しています。\nBalancing weightsを用いると、バランス後の平均値は以下のように計算できます\n\\[2021年のバランス後の平均値 =2021年の(\\omega(X_i,2021)\\times Y_i)の平均値\\]\n\\[2022年のバランス後の平均値 =2022年の(\\omega(X_i,2022)\\times Y_i)の平均値\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Balancing Weight</span>"
    ]
  },
  {
    "objectID": "03BalanceWeight.html#balancing-weightの定義",
    "href": "03BalanceWeight.html#balancing-weightの定義",
    "title": "3  Balancing Weight",
    "section": "",
    "text": "Balancing Weight\n\n\n\n\nBalancing weight \\(\\omega(x,d)\\)は、\\(D\\)間での\\(X\\)の分布の乖離を調整するために導入され、以下のように定義する。 \\[D=1における事例割合\\times \\omega(x,1)\\] \\[= D=0における事例割合\\times \\omega(x,0)\\] \\[=ターゲットとなる割合\\]\n定義式を変形すると \\[\\omega(x,d)=\\frac{ターゲットとなる割合}{(D=d)グループにおける割合}\\]\n\nターゲットに比べて過大な事例割合が過大なグループに対しては小さい、過小なグループに対しては大きなWeightを付与する。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Balancing Weight</span>"
    ]
  },
  {
    "objectID": "03BalanceWeight.html#応用上の課題",
    "href": "03BalanceWeight.html#応用上の課題",
    "title": "3  Balancing Weight",
    "section": "3.2 応用上の課題",
    "text": "3.2 応用上の課題\n\\(X\\)の組み合わせの種類に比べて、十分な事例数が存在するのであれば、Balancing weightは、データ上での\\(X\\)の割合を用いて計算できます2。\nしかしながら多くの応用研究では、バランスの対象となる \\(X\\) の数が多く、\\(D=1\\) または \\(D=0\\) のどちらかの事例しか存在しない組み合わせが対象に発生します。 このような組み合わせについては、Balancing weightsを計算することができず、Balanced comparisonが不可能となります。 この問題を解決するために、次節以降で紹介する、OLS (Chapter 4) や機械学習 (Chapter 6) などを用いた「近似的なバランス法」の活用が有用です。\n\n\n\n\nBruns-Smith, David, Oliver Dukes, Avi Feller, and Elizabeth L Ogburn. 2023. “Augmented Balancing Weights as Linear Regression.” arXiv Preprint arXiv:2304.14545.\n\n\nChattopadhyay, Ambarish, Christopher H Hase, and José R Zubizarreta. 2020. “Balancing Vs Modeling Approaches to Weighting in Practice.” Statistics in Medicine 39 (24): 3227–54.\n\n\nStuart, Elizabeth A, Gary King, Kosuke Imai, and Daniel Ho. 2011. “MatchIt: Nonparametric Preprocessing for Parametric Causal Inference.” Journal of Statistical Software.\n\n\nWager, Stefan. 2024. “Causal Inference: A Statistical Learning Approach.” preparation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Balancing Weight</span>"
    ]
  },
  {
    "objectID": "03BalanceWeight.html#footnotes",
    "href": "03BalanceWeight.html#footnotes",
    "title": "3  Balancing Weight",
    "section": "",
    "text": "因果推論の文脈では、平均効果 (Average Treatment Effect) と呼ばれています。↩︎\nこの方法はExact MatchingやStratified Estimation (Wager 2024) として知られる方法による推定結果と完全に一致します。 例えばExact Matchingは、MatchIt package (Stuart et al. 2011) などを利用して実装できます。↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Balancing Weight</span>"
    ]
  },
  {
    "objectID": "04OLS.html",
    "href": "04OLS.html",
    "title": "4  OLSによる特徴のバランス",
    "section": "",
    "text": "4.1 OLSによる平均値のバランス\n\\(X\\) の組み合わせが多く、Balancing weightsを計算することが困難な場合、近似的なバランスが有力な方法となります。\n本節では代表的な統計手法であるOLS（重回帰）が、近似的なBalancing weightsを暗黙のうちに計算する手法であることを紹介します。 OLSは分布の特徴を、研究者が定める定式化に応じて、要求するBalanceの精度を変更できることが利点です。 ただし、\\(D\\) 間での\\(X\\)の分布の分断が激しい場合、予期せぬ挙動を示しやすいことに注意が必要です。\n近年の研究により、線型モデルのOLS推定は、近似的な Balanceを達成することが確認されています (Chattopadhyay and Zubizarreta 2023)。 本ノートでは、\\(D=\\{0,1\\}\\)を前提とし、その議論の骨子を紹介します。\n重回帰による推定は、\\(D\\)間で\\(X\\) の平均値をバランスさせた上で、平均値を比較しています。 また「母集団におけるOLSの結果」の推論に悪影響を与える、Weightの分散も可能な限り削減しています。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>OLSによる特徴のバランス</span>"
    ]
  },
  {
    "objectID": "04OLS.html#olsによる平均値のバランス",
    "href": "04OLS.html#olsによる平均値のバランス",
    "title": "4  OLSによる特徴のバランス",
    "section": "",
    "text": "OLSの性質 (Chattopadhyay and Zubizarreta 2023)\n\n\n\n\n\\(Y\\sim D + X_1 + .. + X_L\\) をOLSで推定し算出される \\(D\\) の係数値は、以下の方法で計算される値と完全に一致する\n\n\nすべての\\(X_l\\) について、以下を満たす \\(\\omega(x,d)\\) を探す。\n\n\\[(D=1)における(\\omega(x,1)\\times X_l)の平均値\\]\n\\[=(D=0)における(\\omega(x,0)\\times X_l)の平均値\\]\n\n1.を満たす\\(\\omega(x,d)\\) の中で、最小の分散を持つ \\(\\omega(x,d)\\) をBalancing Weightsとする\n\\(\\beta_D\\) を以下のように計算する。 \\[\\beta_D=(D=1)における(\\omega(x,1)\\times Y)の平均値\\]\n\n\\[-(D=0)における(\\omega(x,0)\\times Y)の平均値\\]\n\n\n\n\n4.1.1 例\n部屋の広さ (Size) と 築年数 (Tenure) をバランスさせた後に、2022(\\(D=1\\))/2021(\\(D=0\\))年の平均取引価格差を推定します。 \\(Price\\sim D + Size + Tenure\\) をOLSで推定したとします。\n\nestimatr::lm_robust(\n  Price ~ D + Size + Tenure, \n  Data)\n\nこの推定によって得られる \\(D\\) の係数値は、以下のようなバランスを達成するBalancing Weightsを用いた平均差と一致します。\n\n\n\n\n\n\n\n\n\n赤点 (Unadjusted) は、バランス前の単純平均差を表します。 価格が大きく上昇していますが、取引物件の部屋の広さは狭くなり、築年数は古くなっています。 青点 (Adjusted)は、OLSによる暗黙のバランス後の差を示しています。 SizeやTenureの平均値は完全にバランスしており、結果平均取引価格差も上昇しています。 Tenure2やSize2は、築年数や部屋の広さの二乗項(分散)、Tenure_Sizeは交差項(共分散)を示しており、これらについてはバランスしていません。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>OLSによる特徴のバランス</span>"
    ]
  },
  {
    "objectID": "04OLS.html#olsによる分散や共分散のバランス",
    "href": "04OLS.html#olsによる分散や共分散のバランス",
    "title": "4  OLSによる特徴のバランス",
    "section": "4.2 OLSによる分散や共分散のバランス",
    "text": "4.2 OLSによる分散や共分散のバランス\n\\(Price\\sim D + Size + Tenure\\) を推定しても、SizeやTenureの平均値のみしかバランスできません。 一見、これはOLSの致命的な弱点のように見えますが、簡単な修正によって解決できます\n分散や共分散もバランスさせるためには、二乗項や交差項もモデルに導入したモデル \\[Price\\sim D + Size + Tenure + Size^2 + Tenure^2 + Tenure\\times Size\\] をOLS推定します。\n\nestimatr::lm_robust(\n  Price ~ D + Size + Tenure +\n    I(Size^2) + I(Tenure^2) +\n    (Size + Tenure)**2, \n  Data)\n\nこれによって、Sizeの二乗の”平均値”などもバランスさせることができます。 これは各変数の分散や共分散をバランスを意味します。 結果、以下の図の通り、分散や共分散もBalanceします。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>OLSによる特徴のバランス</span>"
    ]
  },
  {
    "objectID": "04OLS.html#母集団の推定方法",
    "href": "04OLS.html#母集団の推定方法",
    "title": "4  OLSによる特徴のバランス",
    "section": "4.3 母集団の推定方法",
    "text": "4.3 母集団の推定方法\n推定するパラメタ (\\(\\beta_0,..,\\beta_L\\)) に比べて事例数が十分に大きければ、データ上のOLSの結果は、「母集団におけるOLSの結果」の優れた推定値です1。 特に近似的に計算される信頼区間を用いれば、母集団におけるOLSの結果を、定量的に議論できます。\n以下では一切の\\(X\\)をバランスさせないケース、SizeとTenureの平均値のみをバランスさせるケース、平均に加えて分散と共分散もバランスさせたケースの推定結果を、\\(95\\%\\) 信頼区間とともに比較しています。\n\n\n\n\n\n\n\n\n\nコントロールをしないケースに比べて、SizeやTenureをバランスさせると、2022年と2021年の平均差が大きくなりました。 一方で本データについては、平均値に加えて分散や共分散をバランスさせたとしても、あまり大きな変化は生じませんでした。\nまた信頼区間に焦点を当てるとバランス後の平均差の方は、前に比べて、より「狭く」なっています。 これは、母集団におけるOLSの結果とデータ上のOLSの結果が、大きく乖離する可能性が減少している (と推測できる) ことを反映しています。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>OLSによる特徴のバランス</span>"
    ]
  },
  {
    "objectID": "04OLS.html#実践への示唆",
    "href": "04OLS.html#実践への示唆",
    "title": "4  OLSによる特徴のバランス",
    "section": "4.4 実践への示唆",
    "text": "4.4 実践への示唆\n実践における課題は、\\(X\\) について適切な複雑さを持つモデルを設定することです。 しかしながら適切な複雑性は、母集団の特徴や事例数などに依存しており、一般 な解決は困難です。 ただし過去の実践の問題点、および実践上の示唆を得ることはできます。\n多くの研究で\\(X\\)の二乗項や交差項を導入しない推定が行われてきました。 しかしながらこのような推定は、平均値のみのバランスにとどまり、不十分な可能性が高いと考えられます。 例えば、NBER Summer Institute 2018における、Esther Dufloのチュートリアル では、連続変数については二乗項、および全変数について交差項を導入した推定を行なっています。\n複雑な推定は、母集団における推定結果の推論を困難にします。 この問題は、事例数が少ない小規模データを用いた推定において深刻です。 しかしながら現代的な分析環境のもとでは、1000事例を超えるデータを用いた推定が一般的になっています。 このため、バランスさせたい\\(X\\)の数が少ない場合、その二乗項や交差項を加えたとしても、悪影響は小さいと考えられます。 少なくとも小規模事例を用いた推定よりも、より複雑なモデルを推定すべきであると考えられます。\nバランスさせたい変数 \\(X\\) の数が多い場合、二乗項や交差項を導入するとモデルが爆発的に複雑化し、OLSでは推定できなくなります。 このような場合は、Chapter 6 で議論する通り、機械学習を応用が有力です。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>OLSによる特徴のバランス</span>"
    ]
  },
  {
    "objectID": "04OLS.html#実践上の課題",
    "href": "04OLS.html#実践上の課題",
    "title": "4  OLSによる特徴のバランス",
    "section": "4.5 実践上の課題",
    "text": "4.5 実践上の課題\nOLSにより暗黙のうちに計算されるWeightは、平均値をバランスします。 しかしながら、Balancing weightsに求められる他の性質は必ずしも満たされません。 以下、OLSの抱える問題点を列挙します。\n以降の章で紹介する手法の利点は、このOLSが抱える問題点を改善することにあります。 このため発展的な手法を理解し、活用するためにも、OLSの問題点をしっかり認識する必要があります。\n\n4.5.1 定式化\nOLSにおいては、分布の特徴をどこまでバランスさせるのかが問題となります。 事例数が十分あれば、3乗項などの多くの特徴をバランスさせることが可能です。 しかしながら事例数が少ない場合、大量のモーメントをバランスさせると、推定誤差が大きくなってしまいます。 このため事例数に応じて、バランスの対象とする特徴の数を選択する必要があります。 しかしながら実際の応用において、このような選択を適切に行うことは困難です。\nこの問題に対して、Chapter 6 では機械学習を用いた改善方法を紹介します。\n\n\n4.5.2 ターゲット割合\nバランス後の\\(X\\) の平均値がどのような水準になるのか、一般に不透明です。 結果を解釈するためには、\\(X\\) の平均値は明確な水準、例えばデータ全体での平均値と一致させることが望まれます。 しかしながら、OLSはそのような水準との一致を保証しません。\nOLSによるバランス後の\\(X\\)の平均値について、lmw packageにより診断できます。\n\n\n\n\n\n\n\n\n\n黒丸はOLSによるバランス後、ばつ印はバランス前の平均値を示しています。 Control groupは、\\(D=0\\) (2021年)、Treatment groupは、\\(D=1\\) (2022年)の値です。 0線は、サンプル平均を示しています。\n同図からバランス前は、2022年についてはSizeがサンプル平均よりも小さく、Tenureは長くなっています。 黒丸を見るとOLSによるバランス後は、2022年と2021年の間で平均差がなくなることが確認できます。 ただし０線からは乖離しており、サンプル平均とは一致していないことが確認できます。\nこの問題の解決としては、サンプル平均にバランスさせることを明示的に要求したBalancing Weightの算出 (Chapter 5) が有力です。\n\n\n4.5.3 負のウェイト\nBalancing weightsは、正の値を取ることが望まれます。 しかしながらOLSが生成するWeightは、負の値を取る可能性があり、ミスリードな推定結果をもたらす可能性があります。\nlmw packageは、OLSが生成するweightsの値を計算します。 例えばhist関数により、ヒストグラムとして可視化できます。\n\n\n\n\n\n\n\n\n\n本応用例では、負のweightsは発生していないことが確認できました。\n負のweightsが発生しない方法としては、明示的なBalancing Weightの算出 (Chapter 5) や機械学習を活用した柔軟な推定 (Chapter 6)が有力です。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>OLSによる特徴のバランス</span>"
    ]
  },
  {
    "objectID": "04OLS.html#rによる実践例",
    "href": "04OLS.html#rによる実践例",
    "title": "4  OLSによる特徴のバランス",
    "section": "4.6 Rによる実践例",
    "text": "4.6 Rによる実践例\n\n\\(D\\)と\\(X\\)の交差項を含めたモデルのOLS推定、およびその性質の診断は、以下のパッケージを用いて実装できます。\n\nreadr (tidyverseに同梱): データの読み込み\nlmw: OLSが計算するbalance weightsを計算\n\nRepository\n\nestimatr: OLSをRobust standard errorとともに計算\n\nRepository\n\ndotwhisker: 信頼区間の可視化\n\nRepository\n\n\n\n\n4.6.1 準備\nデータを取得します。 \\(D\\) として、取引年が2022か2021かで、1/0となる変数を定義します。 シンプルな比較分析について信頼区間は、データ分割は不要です。\n\nData = readr::read_csv(\"Public.csv\") # データ読み込み\n\nData = dplyr::mutate(\n  Data,\n  D = dplyr::if_else(\n    TradeYear == 2022,1,0\n  ) # 2022年に取引されれば1、2021年に取引されていれば0\n)\n\n\n\n4.6.2 OLSによるバランス\n\\(D\\) 間でSize,Tenure,StationDistanceの平均値をバランスさせ、Priceの平均値を比較します。 また比較のために、一才のバランスを行わない比較結果も併記します。\n\nModel_NoBalance = estimatr::lm_robust(\n  Price ~ D,\n  Data) # OLS推定\n\nModel = estimatr::lm_robust(\n  Price ~ D + Size + Tenure + StationDistance,\n  Data) # OLS推定\n\ndotwhisker::dwplot(\n  list(バランスなし = Model_NoBalance, 平均値のみ = Model),\n  vars_order = \"D\") + # 信頼区間の可視化\n  ggplot2::theme_bw() # 背景を白地化\n\n\n\n\n\n\n\n\n\\(D\\) の係数値は3.29であり、バランス後も中心6区の物件の方が平均取引価格が高いことがわかります。 また信頼区間を考慮することで、母集団においても、中心6区の物件の方が平均取引価格が高い傾向があることがわかります。\n次に各変数の分散と共分散もバランスさせます\n\nModelLong = estimatr::lm_robust(\n  Price ~ D + \n    (Size + Tenure + StationDistance)**2 + # 交差項の作成\n    I(Size^2) + I(Tenure^2) + I(StationDistance^2), # 分散\n  Data)\n\nバランスをしない単純比較も含めて、推定結果を比較すると以下のようになります。\n\ndotwhisker::dwplot(\n  list(\n    バランスなし = Model_NoBalance,\n    平均のみ = Model,\n    `平均/分散/共分散` = ModelLong\n    ),\n  vars_order = \"D\"\n  ) +\n  ggplot2::theme_bw()\n\n\n\n\n\n\n\n\nバランスすることで、推定値が大きくなり、信頼区間が縮小する(推定精度が改善する)ことが確認できます。\n\n4.6.2.1 Balanced Weight\nlmw パッケージのlmw関数を用いれば、OLSが算出しているBalance weightsを計算できます。\n\nMatch = lmw::lmw(\n  ~ D + I(Size^2) + I(Tenure^2) + I(StationDistance^2) +\n               (Size + Tenure + StationDistance)**2, # 平均、分散、共分散をバランス\n  Data\n) # Weightの算出\n\nsummary(Match$weights) # Weightの記述統計量を図示\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7005  0.9685  1.0014  1.0000  1.0335  1.3118 \n\n\n負のWeightが発生していないことが確認できます。\nデータ全体での平均値との乖離も、以下のとおり確認できます。\n\nplot(summary(Match), abs = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nChattopadhyay, Ambarish, and José R Zubizarreta. 2023. “On the Implied Weights of Linear Regression for Causal Inference.” Biometrika 110 (3): 615–29.\n\n\nChernozhukov, Victor, Christian Hansen, Nathan Kallus, Martin Spindler, and Vasilis Syrgkanis. 2024. “Applied Causal Inference Powered by ML and AI.” arXiv Preprint arXiv:2403.02467.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>OLSによる特徴のバランス</span>"
    ]
  },
  {
    "objectID": "04OLS.html#footnotes",
    "href": "04OLS.html#footnotes",
    "title": "4  OLSによる特徴のバランス",
    "section": "",
    "text": "詳細に関心がある読者は、Chernozhukov et al. (2024) の１章などを参照ください。↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>OLSによる特徴のバランス</span>"
    ]
  },
  {
    "objectID": "05Entropy.html",
    "href": "05Entropy.html",
    "title": "5  直接的なBalancing Weightの算出",
    "section": "",
    "text": "5.1 算出方法\nHainmueller (2012) や Zubizarreta (2015) では、Balancing Weightを明示的な”最小化問題”の解として算出します。 このようなアプローチは、満たすべき条件(負の荷重が生じない/サンプル平均にバランスするなど）を課した上で、Balancing Weightが算出できます。 このためOLSによる暗黙のBalancingに比べて、より透明性の高い分析が可能です。\nBalancing Weightについて、以下のような制約を課します。\n上記の制約を満たす\\(\\omega(d,x)\\) のなかで、最もばらつきが小さいものをBalancing Weightとします。 ばらつきの測定方法は、いくつかの提案があります。\n特にentropy divergenceを用いる Hainmueller (2012) の方法は、実際の計算も早く実用的です。 以下では、実際の実装方法を紹介します。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>直接的なBalancing Weightの算出</span>"
    ]
  },
  {
    "objectID": "05Entropy.html#算出方法",
    "href": "05Entropy.html#算出方法",
    "title": "5  直接的なBalancing Weightの算出",
    "section": "",
    "text": "全ての\\(X_l\\)について、その加重平均をデータ全体の平均値に一致させる: \\[(D=1)における(\\omega(x,1)\\times X_l)の平均値\\] \\[= (D=0)における(\\omega(x,0)\\times X_l)の平均値\\] \\[= X_lのデータ全体での平均値\\]\n全てのWeightは非負の値をとる: \\[\\omega(x,d)\\ge 0\\]\n\n\n\nHainmueller (2012) : \\(\\omega(x,d)\\) のentropy divergence \\(\\omega(x,d)\\log(\\omega(x,d)/q)\\)\n\n\\(q\\) はbase weightと呼ばれ、例えば \\(q=1/事例数\\) が用いられます。\n\nZubizarreta (2015) : \\(\\omega(x,d)\\) の分散",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>直接的なBalancing Weightの算出</span>"
    ]
  },
  {
    "objectID": "05Entropy.html#rによる実践例",
    "href": "05Entropy.html#rによる実践例",
    "title": "5  直接的なBalancing Weightの算出",
    "section": "5.2 Rによる実践例",
    "text": "5.2 Rによる実践例\n\n\\(D\\)と\\(X\\)の交差項を含めたモデルのOLS推定、およびその性質の診断は、以下のパッケージを用いて実装できます。\n\nreadr (tidyverseに同梱): データの読み込み\nWeightIt: entroy weightの計算\n\nRepository\n\nmarginaleffects: WeightItパッケージが計算するWeightを用いた推定\n\nRepository\n\n\n\n\n5.2.1 準備\nデータを取得します。 \\(D\\) として、立地が中心6区か否かで、1/0となる変数を定義します。\n\nData = readr::read_csv(\"Public.csv\") # データ読み込み\n\nData = dplyr::mutate(\n  Data,\n  D = dplyr::if_else(\n    LargeDistrict == \"中心6区\",1,0\n  ) # 中心6区に立地していれば1、それ以外は0\n)\n\nベンチマークとして、一切のバランスを行わない単純差、およびOLSによるバランスを行った結果を示します。\n\nModel_No = estimatr::lm_robust(Price ~ D, Data)\n\nModel_OLS = estimatr::lm_robust(\n  Price ~ D + (Size + Tenure + StationDistance)**2 +\n    I(Size^2) + I(Tenure^2) + I(StationDistance^2), \n  Data)\n\nModel_No |&gt; \n  generics::tidy() |&gt; \n  dplyr::mutate(\n    Method = \"No Balance\"\n  ) |&gt; \n  dplyr::bind_rows(\n    Model_OLS |&gt; \n  generics::tidy() |&gt; \n  dplyr::mutate(\n    Method = \"Balance by OLS\"\n  )\n  ) |&gt; \n  dplyr::filter(\n    term == \"D\"\n  ) |&gt; \n  ggplot2::ggplot(\n    ggplot2::aes(\n      y = Method,\n      x = estimate,\n      xmin = conf.low,\n      xmax = conf.high\n    )\n  ) +\n  ggplot2::geom_pointrange() +\n  ggplot2::theme_minimal() +\n  ggplot2::geom_vline(\n    xintercept = 0\n  )\n\n\n\n\n\n\n\n\n\n\n5.2.2 Entropy Weightによるバランス\n\\(D\\) 間でSize,Tenure,StationDistanceの平均値をバランスさせ、Priceの平均値を比較します。 まずWeightItパッケージを用いて、Entropy Weightを計算します。 また比較のためにlmwパッケージを用いて、OLS Weightも計算します。\n\nEntropy = WeightIt::weightit(\n  D ~ (Size + Tenure + StationDistance)**2 +\n    I(Size^2) + I(Tenure^2) + I(StationDistance^2),  # 平均、分散、共分散をバランス\n  data = Data,\n  method = \"ebal\", # Entropy Weightを計算\n  estimand = \"ATE\") \n\nOLS = lmw::lmw(\n  ~ D + (Size + Tenure + StationDistance)**2 +\n    I(Size^2) + I(Tenure^2) + I(StationDistance^2),\n  Data\n)\n\nsummary関数を用いて、Weightの分布を確認します。\n\nsummary(Entropy$weights)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2533  0.8622  0.9706  1.0000  1.0877 16.5677 \n\nsummary(OLS$weights)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-0.2343  0.7615  1.0007  1.0000  1.2484  2.7393 \n\n\nOLSを用いると負のBalancing weightが発生していることが確認できます。 対してEntropy weightでは、そのようなweightは生じません。\nEntropy Weightを用いたバランス後の平均差は、marginaleffectsパッケージのavg_comparison関数を用いて、以下のように計算できます。\n\nWeightIt::lm_weightit(\n  Price ~ D*(I(Size^2) + I(Tenure^2) + I(StationDistance^2) +\n    (Size + Tenure + StationDistance)**2),\n  data = Data,\n  weightit = Entropy\n  ) |&gt; \n  marginaleffects::avg_comparisons(variables = \"D\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n     19.9      0.625 31.8   &lt;0.001 736.2  18.7   21.1\n\nTerm: D\nType:  probs \nComparison: 1 - 0\n\n\n引き続き20前後の平均価格差が算出されました。\n最後にバランスなし、OLSによるバランス、Entropy Weightによるバランス、の結果を図示します。\n\nModel_Ent = WeightIt::lm_weightit(\n  Price ~ D*(I(Size^2) + I(Tenure^2) + I(StationDistance^2) +\n    (Size + Tenure + StationDistance)**2),\n  data = Data,\n  weightit = Entropy\n  ) |&gt; \n  marginaleffects::avg_comparisons(variables = \"D\")\n\n\nModel_No |&gt; \n  generics::tidy() |&gt; \n  dplyr::mutate(\n    Method = \"No Balance\"\n  ) |&gt; \n  dplyr::bind_rows(\n    Model_OLS |&gt; \n  generics::tidy() |&gt; \n  dplyr::mutate(\n    Method = \"Balance by OLS\"\n  )\n  ) |&gt; \n  dplyr::filter(\n    term == \"D\"\n  )|&gt; \n  dplyr::bind_rows(\n    tibble::tibble(\n      Method = \"Entropy\",\n      estimate = Model_Ent$estimate,\n      conf.low = Model_Ent$conf.low,\n      conf.high = Model_Ent$conf.high\n    )\n  ) |&gt; \n  ggplot2::ggplot(\n    ggplot2::aes(\n      y = Method,\n      x = estimate,\n      xmin = conf.low,\n      xmax = conf.high\n    )\n  ) +\n  ggplot2::geom_pointrange() +\n  ggplot2::theme_minimal() +\n  ggplot2::geom_vline(\n    xintercept = 0\n  )",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>直接的なBalancing Weightの算出</span>"
    ]
  },
  {
    "objectID": "05Entropy.html#発展",
    "href": "05Entropy.html#発展",
    "title": "5  直接的なBalancing Weightの算出",
    "section": "5.3 発展",
    "text": "5.3 発展\nBalancing Weightを直接算出する方法は、近年改めて注目を集めており、さまざまな提案がなされています。 例えばAuto debiased machine learning (Chernozhukov, Newey, and Singh 2022a, 2022b; Chernozhukov et al. 2022) と呼ばれる手法も、分布をバランスするWeightを機械学習などを用いて直接算出する手法であるとの解釈も提案されています (Bruns-Smith et al. 2023) 。 Energy Weight (Huling and Mak 2024) も、特徴ではなく分布そのものをバランスするWeightの推定を行なっています。\n直接計算する手法は、AIPWなどの間接的な方法 (Chapter 7) に比べて、推定結果が安定しやすいことが利点として挙げられます。\n\n\n\n\nBruns-Smith, David, Oliver Dukes, Avi Feller, and Elizabeth L Ogburn. 2023. “Augmented Balancing Weights as Linear Regression.” arXiv Preprint arXiv:2304.14545.\n\n\nChernozhukov, Victor, Whitney K Newey, and Rahul Singh. 2022a. “Automatic Debiased Machine Learning of Causal and Structural Effects.” Econometrica 90 (3): 967–1027.\n\n\n———. 2022b. “Debiased Machine Learning of Global and Local Parameters Using Regularized Riesz Representers.” The Econometrics Journal 25 (3): 576–601.\n\n\nChernozhukov, Victor, Whitney Newey, Vıctor M Quintas-Martınez, and Vasilis Syrgkanis. 2022. “Riesznet and Forestriesz: Automatic Debiased Machine Learning with Neural Nets and Random Forests.” In International Conference on Machine Learning, 3901–14. PMLR.\n\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies.” Political Analysis 20 (1): 25–46.\n\n\nHuling, Jared D, and Simon Mak. 2024. “Energy Balancing of Covariate Distributions.” Journal of Causal Inference 12 (1): 20220029.\n\n\nZubizarreta, José R. 2015. “Stable Weights That Balance Covariates for Estimation with Incomplete Outcome Data.” Journal of the American Statistical Association 110 (511): 910–22.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>直接的なBalancing Weightの算出</span>"
    ]
  },
  {
    "objectID": "06R.html",
    "href": "06R.html",
    "title": "6  機械学習の活用: 残差回帰",
    "section": "",
    "text": "6.1 OLSの一般化\n\\(X\\) の数が多い場合、OLSを用いた分布の特徴のバランスは、難しくなります。 これはどのような特徴をバランスさせるのか、研究者の裁量の余地が大きくなりすぎるためです。 このような研究者による推定式の定式化に起因する推定結果のブレは、Model Uncertainly (Varian 2014) とも呼ばれ、分析の信頼性を脅かす大きな要因となっています。\nこのような問題への対応として、機械学習を有効活用した、よりデータ主導のアプローチが注目されて来ました (Varian 2014; Urminsky, Hansen, and Chernozhukov 2019)。 近年、機械学習の中でも教師付き学習の手法を、バランス後の比較に応用する方法について理解が急速に進みました。 その中で教師付き学習 (より一般にはノンパラメトリック/データ適合的な推定) が持つ弱点である「収束の遅さ」1を補完する方法が開発されています。 このような方法を用いることで、信頼区間の近似計算など、母集団への含意がより明確な推定が可能となります。\n本章は、OLSの直接的な拡張と解釈できる 残差回帰 への応用を紹介します2。\nOLSを用いて、\\(X\\)の分布を完全にバランスさせるには、以下のようなモデルを推定する必要があリます。\n\\[Y\\sim D + \\underbrace{f(X_1,..,X_L)}_{Xについての極めて複雑な式}\\] \\(f(X_1,..,X_L)\\) は、一般に無限個のパラメタを持つ式となります。\n例えば1つの連続変数, \\(X_1\\), のみのバランスが目標であるとします。 この場合でも、推定式は以下のように無限個のパラメタを持つ式として定式化できます。\n\\[f(X_1)=\\underbrace{\\beta_0 + \\beta_{1}X_1 + \\beta_{2}X_1^2 + \\beta_{3}X_1^3...}_{無限和}\\]\nこのような無限個のパラメタを持つ式を、OLSで推定することは不可能です。 あるいはパラメタの数が有限個であったとしても、データの事例数を超えると推定が不可能になります3。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>機械学習の活用: 残差回帰</span>"
    ]
  },
  {
    "objectID": "06R.html#残差回帰",
    "href": "06R.html#残差回帰",
    "title": "6  機械学習の活用: 残差回帰",
    "section": "6.2 残差回帰",
    "text": "6.2 残差回帰\n残差回帰は、\\(Y\\sim D + f(X_1,..,X_L)\\) が以下のように書き換えることができることに基づいています。\n\\[\\underbrace{Y - (X内での)Yの平均値}_{Yの残差}\\sim \\underbrace{D - (X内での)Dの平均値}_{Dの残差}\\] すなわち \\(Y\\) の残差と \\(D\\) の残差を単回帰すれば、バランス後の平均値の比較を達成できます。\n残る課題は、\\(Y\\) と \\(D\\) の平均値をデータから推定することです。 このような推定は、\\(X\\) が多くある場合、困難な課題でした。 以下、OLS推定を再解釈することで、どのような問題が生じるのか示します。\n\n6.2.1 OLSの再解釈\nFWL 定理 (wiki) は、OLSも残差回帰として解釈できることを示しています。\nOLSによって推定された\\(D\\)の係数値は、以下の手順で計算された値と厳密に一致します。\n\n\n\n\n\n\nFWL(Frisch–Waugh–Lovell) 定理\n\n\n\n\nY/D/Xを設定\n全データを用いて、\\(Y\\) , \\(D\\) の平均値の推定値 \\(f_Y(X), f_D(X)\\)を \\(Y\\sim\\beta_0 + \\beta_1X_1 +.. + \\beta_LX_L\\) および \\(D\\sim\\beta_0 + \\beta_1X_1 +.. + \\beta_LX_L\\) をOLS推定することで算出\n残差 \\(Y - f_Y(X)\\) と \\(D - f_D(X)\\) を計算\n残差同士を回帰する: \\(Y - f_Y(X)\\sim D - f_D(X)\\)\n\n\n\n\\(X\\) が多い場合、 Step 1.が大きな問題を抱えます。 一般にパラメタ \\((\\beta_0..\\beta_L)\\) の数が、事例数に近い値になると、 平均値の推定値は\\(Y\\),\\(D\\)の実際の値に限りなく近づいていきます。 このような現象は、過剰適合、あるいは過学習と呼ばれています。\n機械学習の応用では、Step 1.を\\(Y\\) と \\(D\\) を\\(X\\)から予測する問題と捉えます。 このような予測問題においては、OLSも含めたさまざまな推定手法を用いることができます。\n\n\n6.2.2 教師付き学習の応用\nある一つの連続/カテゴリー変数 \\(Y\\) や \\(D\\) と(大量の)変数 \\(X\\) の関係性の推定は、教師付き学習の中心的な研究課題です。 中でも、(\\(X\\)内での) \\(Y\\) や \\(D\\) の平均値の推定については、膨大な研究成果が蓄積されています4。\n一般に教師付き学習は、ある結果変数の予測を目的としています。 予測の精度を平均二乗誤差で測定する場合、理論上最善の予測値は、(\\(X\\)内での)母平均であることが容易に証明できます。 このため、(\\(X\\)内での)母平均を近似できるモデルの推定が、教師付き学習の実質的な目標となります。 この性質を利用することで、既存の機械学習の方法で推定された予測モデルを、平均値を近似するモデルとして利用することができます。\n予測モデルを推定する際には、Section 6.3 で議論する優れた推定上の性質を達成するために、交差推定を活用することが、一般に推奨されます (Naimi, Mishler, and Kennedy 2023)5。\n\n\n\n\n\n\n交差推定 (Cross Validation)\n\n\n\n\nデータを細かく分割 (第1,..,10 サブグループなど)\n第1サブグループ以外で推定して、第1サブグループの予測値を算出\n第2…サブグループについて、繰り返し、全事例に対して予測値を算出\n\n\n\n推定に用いるアルゴリズムとしては、複数の予測モデルを組み合わせるStacking法が推奨されます(Ahrens et al. 2025; Naimi, Mishler, and Kennedy 2023)。 これは多くの社会分析において、高い予測性能を期待できるアルゴリズムを事前に選択することが困難であるためです。\n交差推定を活用した、残差回帰の具体的な推定手順は以下となります。\n\n\n\n\n\n\n機械学習を活用した残差回帰\n\n\n\n\nY/D/Xおよび予測に使用するアルゴリズムを設定\n交差推定を用いて、YとDを予測するモデル \\(f_Y(X)\\) と \\(f_D(X)\\) を推定する\n残差 \\(Y - f_Y(X)\\) と \\(D - f_D(X)\\) を計算する\n\n予測誤差とも解釈できます。\n\n残差同士を回帰する: \\(Y - f_Y(X)\\sim D - f_D(X)\\)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>機械学習の活用: 残差回帰</span>"
    ]
  },
  {
    "objectID": "06R.html#sec-Estimation_R",
    "href": "06R.html#sec-Estimation_R",
    "title": "6  機械学習の活用: 残差回帰",
    "section": "6.3 母集団の推定方法",
    "text": "6.3 母集団の推定方法\n交差推定を併用した残差回帰の利点は、「母集団上で\\(X\\)を完全にバランスさせた後に計算した平均差」について、推論が可能なことです。 特に交差推定とStackingなどの柔軟な方法で予測モデルを推定すれば、緩やかな仮定のみで信頼区間を近似計算が可能です (Chernozhukov et al. 2018)。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>機械学習の活用: 残差回帰</span>"
    ]
  },
  {
    "objectID": "06R.html#応用上の課題",
    "href": "06R.html#応用上の課題",
    "title": "6  機械学習の活用: 残差回帰",
    "section": "6.4 応用上の課題",
    "text": "6.4 応用上の課題\n機械学習を活用した残差回帰は、OLSの持つ幾つかの問題点を改善します。\n十分な事例数があれば、「母集団上で\\(X\\)を完全にバランスさせた後に計算した平均差」を近似するため、負の荷重問題は生じません。\n定式化そのものではなく、推定方法を選ぶため、Researcher degrees of freedom を適切に軽減できる可能性があります(Urminsky, Hansen, and Chernozhukov 2019; Ludwig, Mullainathan, and Spiess 2019) 。 特に複数の推定方法を組み合わせるStacking法とシード値の適切な管理6によっては、研究者への依存度を低下させられます。\n問題点としては、ターゲットの解釈が容易ではないことが知られています。 母集団上での残差回帰は、\\(X\\)を完全にバランスさせますが、そのターゲットは、以下となります。\n\\[\\frac{(X内での)D=1の割合\\times (X内での)D=0 の割合}{(X内での)D=1の割合\\times (X内での)D=0 の割合の平均値}\\]\nこのようなターゲットは、Overlap Weightとも呼ばれています。\nOverlap Weightをターゲットとすると、\\(D\\)のばらつきが大きいグループの平均値を、最終的な比較結果に強く反映します。 \\(D\\)のばらつきが無いグループ (\\(D=0\\) または \\(D=1\\) しか存在しない) の加重は0であり、最終的な比較結果に一才の影響を与えません。 このためOverlapの仮定 (Important 1.1) を「必ず」満たすことできます。\nこのような優れた性質を持つ一方で、このターゲットをどのように解釈すればいいのか、一般に不透明です。 特に\\(X\\)間での\\(D\\)の偏りが大きい場合、Overlap Weightのばらつきも大きくなり、解釈が一層難しくなります。 Zhou and Opacic (2022) など、Overlap Weightの解釈を提供する研究は行われていますが、確立された解釈は現状ありません。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>機械学習の活用: 残差回帰</span>"
    ]
  },
  {
    "objectID": "06R.html#rによる実践例",
    "href": "06R.html#rによる実践例",
    "title": "6  機械学習の活用: 残差回帰",
    "section": "6.5 Rによる実践例",
    "text": "6.5 Rによる実践例\n\n以下のパッケージを使用\n\nreadr (tidyverseに同梱): データの読み込み\nddml: 残差回帰の実施\n\nmannual\n\n\n\n\n6.5.1 準備\nddmlパッケージの関数を用いる場合、事前にYとDはベクトルとして、Xは行列として定義する必要があります。\n\nset.seed(111) # シード値を固定\n\nData = readr::read_csv(\"Public.csv\")\n\nData = dplyr::mutate(\n  Data,\n  D = dplyr::if_else(\n    TradeYear == 2022,1,0\n  ) # 2022年に取引されれば1、2021年に取引されていれば0\n)\n\nY = Data$Price # Yの定義\nD = Data$D # Dの定義\nX = Data |&gt; \n  select(\n    District,\n    Size,\n    Tenure,\n    StationDistance\n  ) |&gt; \n  data.matrix() # Xの定義\n\n\n\n6.5.2 残差回帰\n残差回帰は、ddmlパッケージのddm_plm関数を用いて実装できます。\n\nModel = ddml::ddml_plm(\n  y = Y, # Yの指定\n  D = D, # Dの指定\n  X = X, # Xの指定\n  learners = list(\n    list(fun = ddml::ols), # OLSを使用\n    list(fun = ddml::mdl_ranger) # RandomForestを使用\n  ),\n  shortstack = TRUE, # 簡略化した推定手順を指定\n  silent = TRUE # Messageを非表示\n  )\n\nModel |&gt; summary()\n\nPLM estimation results: \n \n, , nnls\n\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   -0.374      0.157   -2.38 1.73e-02\nD_r            3.730      0.328   11.38 5.01e-30\n\n\nsummary関数は、推定値 (Estimate)、標準誤差 (Std. Error)、t値 (t value)、 p値 (Pr(&gt;|t|)) を報告しています。 バランス後の平均差は、D_rです。\n95\\(\\%\\)信頼区間は以下のように計算できます。\n\nSum = summary(Model)\n\nEst = Sum[2,1,1] # 推定値\nSD = Sum[2,2,1] # 標準誤差\n\nc(Est - 1.96*SD, Est + 1.96*SD) # 信頼区間の下限、上限\n\n[1] 3.088172 4.372682\n\n\n\n\n\n\nAhrens, Achim, Christian B Hansen, Mark E Schaffer, and Thomas Wiemann. 2025. “Model Averaging and Double Machine Learning.” Journal of Applied Econometrics.\n\n\nChen, Qizhao, Vasilis Syrgkanis, and Morgane Austern. 2022. “Debiased Machine Learning Without Sample-Splitting for Stable Estimators.” Advances in Neural Information Processing Systems 35: 3096–3109.\n\n\nChernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. “Double/Debiased Machine Learning for Treatment and Structural Parameters.” The Econometrics Journal 21 (1): C1–68.\n\n\nChernozhukov, Victor, Christian Hansen, Nathan Kallus, Martin Spindler, and Vasilis Syrgkanis. 2024. “Applied Causal Inference Powered by ML and AI.” arXiv Preprint arXiv:2403.02467.\n\n\nDı́az, Iván. 2020. “Machine Learning in the Estimation of Causal Effects: Targeted Minimum Loss-Based Estimation and Double/Debiased Machine Learning.” Biostatistics 21 (2): 353–58.\n\n\nFisher, Aaron, and Edward H Kennedy. 2021. “Visually Communicating and Teaching Intuition for Influence Functions.” The American Statistician 75 (2): 162–72.\n\n\nHines, Oliver, Oliver Dukes, Karla Diaz-Ordaz, and Stijn Vansteelandt. 2022. “Demystifying Statistical Learning Based on Efficient Influence Functions.” The American Statistician 76 (3): 292–304.\n\n\nIchimura, Hidehiko, and Whitney K Newey. 2022. “The Influence Function of Semiparametric Estimators.” Quantitative Economics 13 (1): 29–61.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, et al. 2021. An Introduction to Statistical Learning. Vol. 112. Springer.\n\n\nKennedy, Edward H. 2024. “Semiparametric Doubly Robust Targeted Double Machine Learning: A Review.” Handbook of Statistical Methods for Precision Medicine, 207–36.\n\n\nLudwig, Jens, Sendhil Mullainathan, and Jann Spiess. 2019. “Augmenting Pre-Analysis Plans with Machine Learning.” In Aea Papers and Proceedings, 109:71–76. American Economic Association 2014 Broadway, Suite 305, Nashville, TN 37203.\n\n\nNaimi, Ashley I, Alan E Mishler, and Edward H Kennedy. 2023. “Challenges in Obtaining Valid Causal Effect Estimates with Machine Learning Algorithms.” American Journal of Epidemiology 192 (9): 1536–44.\n\n\nNaimi, Ashley I, Ya-Hui Yu, and Lisa M Bodnar. 2024. “Pseudo-Random Number Generator Influences on Average Treatment Effect Estimates Obtained with Machine Learning.” Epidemiology 35 (6): 779–86.\n\n\nRenson, Audrey, Lina Montoya, Dana E Goin, Iván Dı́az, and Rachael K Ross. 2025. “Pulling Back the Curtain: The Road from Statistical Estimand to Machine-Learning Based Estimator for Epidemiologists (No Wizard Required).” arXiv Preprint arXiv:2502.05363.\n\n\nSchader, Lindsey, Weishan Song, Russell Kempker, and David Benkeser. 2024. “Don’t Let Your Analysis Go to Seed: On the Impact of Random Seed on Machine Learning-Based Causal Inference.” Epidemiology 35 (6): 764–78.\n\n\nSchuler, Alejandro, and Mark van der Laan. 2024. “Introduction to Modern Causal Inference.” preparation.\n\n\nUrminsky, Oleg, Christian Hansen, and Victor Chernozhukov. 2019. “The Double-Lasso Method for Principled Variable Selection.”\n\n\nVarian, Hal R. 2014. “Big Data: New Tricks for Econometrics.” Journal of Economic Perspectives 28 (2): 3–28.\n\n\nWager, Stefan. 2024. “Causal Inference: A Statistical Learning Approach.” preparation.\n\n\nZhou, Xiang, and Aleksei Opacic. 2022. “Marginal Interventional Effects.” arXiv Preprint arXiv:2206.10717.\n\n\nZivich, Paul N. 2024. “Commentary: The Seedy Side of Causal Effect Estimation with Machine Learning.” Epidemiology 35 (6): 787–90.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>機械学習の活用: 残差回帰</span>"
    ]
  },
  {
    "objectID": "06R.html#footnotes",
    "href": "06R.html#footnotes",
    "title": "6  機械学習の活用: 残差回帰",
    "section": "",
    "text": "「収束」の具体的な定義に関心がある方は、wikipediaの記事などを参照ください。↩︎\n機械学習は、より幅広い推定方法に応用できます。一般的な入門としては、Chernozhukov et al. (2024)を推奨します。他の入門資料としても、Wager (2024)、Schuler and Laan (2024)、Ichimura and Newey (2022)、Fisher and Kennedy (2021)、Hines et al. (2022)、Kennedy (2024)、Renson et al. (2025) などの優れた教材が利用できます。簡潔な入門としては、Dı́az (2020) がお勧めです。↩︎\nパラメタと事例数、推定精度の詳細な関係性については、Chernozhukov et al. (2024) の1章とその引用文献を参照ください。↩︎\n詳細は、James et al. (2021) などを参照ください↩︎\n交差推定の利点/欠点については、Chen, Syrgkanis, and Austern (2022) などで重点的に検討されています。↩︎\nNaimi, Yu, and Bodnar (2024), Schader et al. (2024); Zivich (2024)↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>機械学習の活用: 残差回帰</span>"
    ]
  },
  {
    "objectID": "07AIPW.html",
    "href": "07AIPW.html",
    "title": "7  機械学習の活用: AIPW",
    "section": "",
    "text": "7.1 Inverse probability weight\n\\(D\\)間での\\(X\\)の分布を近似的にバランスする手法としては、Inverse Probability Weight (IWP) も有力です。 本手法は、(\\(X\\)内での)\\(D\\)の分布を推定し、その逆数をウェイトとして使用する方法です。 この\\(D\\)の分布は、傾向スコア(Propensity Score)と呼ばれています。 特に \\(Y\\) の推定されたモデルと組みわせるAugmented Inverse Probability Weightは、機械学習などを用いた柔軟な推定と信頼区間の近似計算などの統計的推論と両立できます。\n傾向スコアを活用した代表的な推定手法は、Inverse probability weightです。 この手法は、ベイズルールによるBalancing weightsの書き換えに基づいています。 ただしこの手法は、傾向スコアの推定精度に強く依存します。 また一般に推定精度が悪い傾向があります1。 このため本ノートでは、Section 7.2 で紹介するArgumented inverse probability weight (AIPW)の活用を推奨します。\nBalancing Weight \\(\\omega(d,x)\\) は以下のように定義されました。 \\[\\omega(d,x)=\\frac{ターゲット割合}{D=dにおけるX=xの事例割合}\\]\nベイズルールを適用すると \\(\\omega(d,x)\\) は以下のように書き換えられます。\n\\(D=d\\)の割合は、データ内での\\(D=d\\)の割合などを用いて、容易に推定できます。 よって傾向スコアが推定できれば、Balancing Weightの計算が可能です。 推定された傾向スコアを用いたBalanced comparisonはInverse probability weightと呼ばれ、以下の手順としてまとめられます。\nこの手法は 傾向スコアの推定には、\\(D\\)を\\(X\\)で回帰する標準的な方法を用いることができます。 例えばLogitやProbitなどのパラメトリックな手法やRandom ForestやBoosting、Deep Learningなどの機械学習の手法も活用可能です。\nしかしながらどちらの手法を用いたとしても、推定上の問題があります。 IPWによる推定結果は、傾向スコアの推定精度に強く依存します。 このためLogitやProbitを用いた場合、推定モデルの定式化を正しく行う必要がありますが、多くの応用で困難です。 対して機械学習の手法を用いた場合、推定結果の収束の遅さが問題となり、信頼区間の近似計算などが難しくなります。\nこの問題に対して、\\(Y\\) の平均値の推定値 \\(f_Y(D,X)\\) を併用するAugmented Inverse Probability Weightが有力です。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>機械学習の活用: AIPW</span>"
    ]
  },
  {
    "objectID": "07AIPW.html#inverse-probability-weight",
    "href": "07AIPW.html#inverse-probability-weight",
    "title": "7  機械学習の活用: AIPW",
    "section": "",
    "text": "Balancing Weightの書き換え\n\n\n\n\\[\\omega(d,x)=\\underbrace{\\frac{1}{X=xにおけるD=dの割合}}_{傾向スコアの逆数}\\] \\[\\times (D=dの割合)\\] \\[\\times \\frac{ターゲット割合}{X=xの割合}\\]\nターゲット割合を\\(X=xの割合\\)とするのであれば、以下のように単純化できる。\n\\[\\omega(d,x)=傾向スコアの逆数\\times D=dの割合\\]\n\n\n\n\n\n\n\n\n\nInverse probability weight\n\n\n\n\n傾向スコアを何らかの手法で推定する\nBalancing weights \\(\\omega(d,x)\\)を計算する\nBalancing weightsで荷重した平均差を計算する \\[D=1における(\\omega(x,1)\\times Y)の平均値\\] \\[-D=0における(\\omega(x,0)\\times Y)の平均値\\]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>機械学習の活用: AIPW</span>"
    ]
  },
  {
    "objectID": "07AIPW.html#sec-sub_AIPW",
    "href": "07AIPW.html#sec-sub_AIPW",
    "title": "7  機械学習の活用: AIPW",
    "section": "7.2 Augmented Inverse Probability Weight",
    "text": "7.2 Augmented Inverse Probability Weight\nAugmented Inverse Probability Weightの手順は以下のようにまとめられます。\n\n\n\n\n\n\nAugmented Inverse Probability Weight\n\n\n\n\n交差推定を用いて、Y,Dを予測するモデル \\(f_Y(D,X)\\) と \\(f_D(X)\\) を推定する\nAIPWの推定値を以下のように補正し、AIPWの推定値を計算する \\[+ f_{Y}(1,X_i)\\frac{D - f_D(X)}{f_D(X)}の平均値\\] \\[-f_{Y}(0,X_i)\\frac{(1 - D) - (1 - f_D(X))}{1-f_D(X)}の平均値\\]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>機械学習の活用: AIPW</span>"
    ]
  },
  {
    "objectID": "07AIPW.html#母集団の推定方法",
    "href": "07AIPW.html#母集団の推定方法",
    "title": "7  機械学習の活用: AIPW",
    "section": "7.3 母集団の推定方法",
    "text": "7.3 母集団の推定方法\n母集団上でのAIPWとデータ上でのAIPWは、残差回帰とよく似た性質を持ちます。 交差推定とStackingなどの柔軟な方法を組み合わせて予測モデルを推定すれば、緩やかな仮定のみで、「母集団上で計算したAugmented Inverse Probability Weight」の結果について、信頼区間の近似計算が可能です。 AIPWは、データ全体での\\(X\\)の分布をターゲット割合としたバランス後の比較です。 このため「母集団上での\\(X\\)の分布をターゲットとした、バランス後の比較」について、信頼区間計算ができます。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>機械学習の活用: AIPW</span>"
    ]
  },
  {
    "objectID": "07AIPW.html#残差回帰との比較",
    "href": "07AIPW.html#残差回帰との比較",
    "title": "7  機械学習の活用: AIPW",
    "section": "7.4 残差回帰との比較",
    "text": "7.4 残差回帰との比較\n残差回帰とAIPWは、よく似た性質を持ち、同じような動機に基づいています2。\n大きな違いは、ターゲット割合です。 残差回帰におけるターゲット割合は、Overlap Weightであり (Chapter 6)、その解釈は困難でした。 対してAIPWでは、\\(X\\) の分布であり、解釈が容易です。 すなわち「もし\\(X\\)の分布がデータ全体のものと一致していた場合、平均差はどのようなものになるか？」という疑問に答えることができます。 このような解釈が容易さが、AIPWの大きな魅力です。\n対してAIPWの弱点は、傾向スコアの値が0や1に近い事例がある場合、推定結果が不安定になりやすい点です。 これは傾向スコアの逆数が推定式に含まれているために生じます。 弊害の具体例としては、計算された信頼区間の拡大や信頼区間の近似計算そのものの信頼性低下、などです。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>機械学習の活用: AIPW</span>"
    ]
  },
  {
    "objectID": "07AIPW.html#rによる実践例",
    "href": "07AIPW.html#rによる実践例",
    "title": "7  機械学習の活用: AIPW",
    "section": "7.5 Rによる実践例",
    "text": "7.5 Rによる実践例\n引き続きddmlパッケージを使用し、AIPW推定は実装できます。\n\n以下のパッケージを使用\n\nreadr (tidyverseに同梱): データの読み込み\nddml: AIPWの実施\n\nmannual\n\n\n\n\n7.5.1 準備\n\\(Y\\)と\\(D\\)はベクトル、\\(X\\)は行列として定義します。\n\nset.seed(111) # シード値を固定\n\nData = readr::read_csv(\"Public.csv\")\n\nData = dplyr::mutate(\n  Data,\n  D = dplyr::if_else(\n    TradeYear == 2022,1,0\n  ) # 2022年に取引されれば1、2021年に取引されていれば0\n)\n\nY = Data$Price\nD = Data$D\nX = Data |&gt; \n  dplyr::select(\n    District,\n    Size,\n    Tenure,\n    StationDistance\n  )\n\n\n\n7.5.2 ATE\nStackingを用いたAIPW推定は、ddml_ate関数を用いて、以下のように実装できます。\n\nModel = ddml::ddml_ate(\n  y = Y,\n  D = D,\n  X = data.matrix(X),\n  learners = list(\n    list(fun = ddml::ols),\n    list(fun = ddml::mdl_ranger)\n  ),\n  shortstack = TRUE, # 簡略化したStacking法を利用\n  silent = TRUE # Messageを非表示\n  )\n\nModel |&gt; summary()\n\nATE estimation results: \n \n     Estimate Std. Error t value Pr(&gt;|t|)\nnnls     3.68      0.339    10.8 2.52e-27\n\n\nsummary関数は、推定値 (Estimate)、標準誤差 (Std. Error)、t値 (t value)、 p値 (Pr(&gt;|t|)) を報告しています。 バランス後の平均差は、nnlsです。\n95\\(\\%\\)信頼区間は以下のように計算できます。\n\nSum = summary(Model)\n\nEst = Sum[1,1] # 推定値\nSD = Sum[1,2] # 標準誤差\n\nc(Est - 1.96*SD, Est + 1.96*SD) # 信頼区間の下限、上限\n\n[1] 3.010346 4.340967\n\n\n\n\n\n\nFisher, Aaron, and Edward H Kennedy. 2021. “Visually Communicating and Teaching Intuition for Influence Functions.” The American Statistician 75 (2): 162–72.\n\n\nHines, Oliver, Oliver Dukes, Karla Diaz-Ordaz, and Stijn Vansteelandt. 2022. “Demystifying Statistical Learning Based on Efficient Influence Functions.” The American Statistician 76 (3): 292–304.\n\n\nIchimura, Hidehiko, and Whitney K Newey. 2022. “The Influence Function of Semiparametric Estimators.” Quantitative Economics 13 (1): 29–61.\n\n\nRenson, Audrey, Lina Montoya, Dana E Goin, Iván Dı́az, and Rachael K Ross. 2025. “Pulling Back the Curtain: The Road from Statistical Estimand to Machine-Learning Based Estimator for Epidemiologists (No Wizard Required).” arXiv Preprint arXiv:2502.05363.\n\n\nWager, Stefan. 2024. “Causal Inference: A Statistical Learning Approach.” preparation.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>機械学習の活用: AIPW</span>"
    ]
  },
  {
    "objectID": "07AIPW.html#footnotes",
    "href": "07AIPW.html#footnotes",
    "title": "7  機械学習の活用: AIPW",
    "section": "",
    "text": "詳細は、Wager (2024) の第２章などを参照ください。↩︎\nどちらもEfficient influence functionを用いて、推定式を導出できます (Ichimura and Newey 2022; Fisher and Kennedy 2021; Hines et al. 2022; Renson et al. 2025)。↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>機械学習の活用: AIPW</span>"
    ]
  },
  {
    "objectID": "Referemce.html",
    "href": "Referemce.html",
    "title": "Reference",
    "section": "",
    "text": "Ahrens, Achim, Christian B Hansen, Mark E Schaffer, and Thomas Wiemann.\n2025. “Model Averaging and Double Machine Learning.”\nJournal of Applied Econometrics.\n\n\nBajari, Patrick, Zhihao Cen, Victor Chernozhukov, Manoj Manukonda, Suhas\nVijaykumar, Jin Wang, Ramon Huerta, et al. 2023. “Hedonic Prices\nand Quality Adjusted Price Indices Powered by AI.” arXiv\nPreprint arXiv:2305.00044.\n\n\nBehaghel, Luc, Bruno Crépon, and Marc Gurgand. 2014. “Private and\nPublic Provision of Counseling to Job Seekers: Evidence from a Large\nControlled Experiment.” American Economic Journal: Applied\nEconomics 6 (4): 142–74.\n\n\nBen-Michael, Eli, Avi Feller, David A Hirshberg, and José R Zubizarreta.\n2021. “The Balancing Act in Causal Inference.” arXiv\nPreprint arXiv:2110.14831.\n\n\nBruns-Smith, David, Oliver Dukes, Avi Feller, and Elizabeth L Ogburn.\n2023. “Augmented Balancing Weights as Linear Regression.”\narXiv Preprint arXiv:2304.14545.\n\n\nChattopadhyay, Ambarish, Christopher H Hase, and José R Zubizarreta.\n2020. “Balancing Vs Modeling Approaches to Weighting in\nPractice.” Statistics in Medicine 39 (24): 3227–54.\n\n\nChattopadhyay, Ambarish, and José R Zubizarreta. 2023. “On the\nImplied Weights of Linear Regression for Causal Inference.”\nBiometrika 110 (3): 615–29.\n\n\nChattopadhyay, Ambarish, and José R. Zubizarreta. 2024. Harvard Data\nScience Review 6 (1).\n\n\nChen, Qizhao, Vasilis Syrgkanis, and Morgane Austern. 2022.\n“Debiased Machine Learning Without Sample-Splitting for Stable\nEstimators.” Advances in Neural Information Processing\nSystems 35: 3096–3109.\n\n\nChernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo,\nChristian Hansen, Whitney Newey, and James Robins. 2018.\n“Double/Debiased Machine Learning for Treatment and Structural\nParameters.” The Econometrics Journal 21 (1): C1–68.\n\n\nChernozhukov, Victor, Juan Carlos Escanciano, Hidehiko Ichimura, Whitney\nK Newey, and James M Robins. 2022. “Locally Robust Semiparametric\nEstimation.” Econometrica 90 (4): 1501–35.\n\n\nChernozhukov, Victor, Christian Hansen, Nathan Kallus, Martin Spindler,\nand Vasilis Syrgkanis. 2024. “Applied Causal Inference Powered by\nML and AI.” arXiv Preprint arXiv:2403.02467.\n\n\nChernozhukov, Victor, Whitney K Newey, and Rahul Singh. 2022a.\n“Automatic Debiased Machine Learning of Causal and Structural\nEffects.” Econometrica 90 (3): 967–1027.\n\n\n———. 2022b. “Debiased Machine Learning of Global and Local\nParameters Using Regularized Riesz Representers.” The\nEconometrics Journal 25 (3): 576–601.\n\n\nChernozhukov, Victor, Whitney Newey, Vıctor M Quintas-Martınez, and\nVasilis Syrgkanis. 2022. “Riesznet and Forestriesz: Automatic\nDebiased Machine Learning with Neural Nets and Random Forests.”\nIn International Conference on Machine Learning, 3901–14. PMLR.\n\n\nDı́az, Iván. 2020. “Machine Learning in the Estimation of Causal\nEffects: Targeted Minimum Loss-Based Estimation and Double/Debiased\nMachine Learning.” Biostatistics 21 (2): 353–58.\n\n\nEgami, Hiroyuki, Md Shafiur Rahman, Tsuyoshi Yamamoto, Chihiro Egami,\nand Takahisa Wakabayashi. 2024. “Causal Effect of Video Gaming on\nMental Well-Being in Japan 2020–2022.” Nature Human\nBehaviour 8 (10): 1943–56.\n\n\nFisher, Aaron, and Edward H Kennedy. 2021. “Visually Communicating\nand Teaching Intuition for Influence Functions.” The American\nStatistician 75 (2): 162–72.\n\n\nGelman, Andrew, Jessica Hullman, and Lauren Kennedy. 2024. “Causal\nQuartets: Different Ways to Attain the Same Average Treatment\nEffect.” The American Statistician 78 (3): 267–72.\n\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A\nMultivariate Reweighting Method to Produce Balanced Samples in\nObservational Studies.” Political Analysis 20 (1):\n25–46.\n\n\nHines, Oliver, Oliver Dukes, Karla Diaz-Ordaz, and Stijn Vansteelandt.\n2022. “Demystifying Statistical Learning Based on Efficient\nInfluence Functions.” The American Statistician 76 (3):\n292–304.\n\n\nHuling, Jared D, and Simon Mak. 2024. “Energy Balancing of\nCovariate Distributions.” Journal of Causal Inference 12\n(1): 20220029.\n\n\nIchimura, Hidehiko, and Whitney K Newey. 2022. “The Influence\nFunction of Semiparametric Estimators.” Quantitative\nEconomics 13 (1): 29–61.\n\n\nImai, Kosuke, and Marc Ratkovic. 2014. “Covariate Balancing\nPropensity Score.” Journal of the Royal Statistical Society\nSeries B: Statistical Methodology 76 (1): 243–63.\n\n\nJackson, John W, and Tyler J VanderWeele. 2018. “Decomposition\nAnalysis to Identify Intervention Targets for Reducing\nDisparities.” Epidemiology (Cambridge, Mass.) 29 (6):\n825.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, et al.\n2021. An Introduction to Statistical Learning. Vol. 112.\nSpringer.\n\n\nKallus, Nathan. 2023. “Treatment Effect Risk: Bounds and\nInference.” Management Science 69 (8): 4579–90.\n\n\nKennedy, Edward H. 2024. “Semiparametric Doubly Robust Targeted\nDouble Machine Learning: A Review.” Handbook of Statistical\nMethods for Precision Medicine, 207–36.\n\n\nLudwig, Jens, Sendhil Mullainathan, and Jann Spiess. 2019.\n“Augmenting Pre-Analysis Plans with Machine Learning.” In\nAea Papers and Proceedings, 109:71–76. American Economic\nAssociation 2014 Broadway, Suite 305, Nashville, TN 37203.\n\n\nMossé, Milan, Kara Schechtman, Frederick Eberhardt, and Thomas Icard.\n2025. “Modeling Discrimination with Causal Abstraction.”\narXiv Preprint arXiv:2501.08429.\n\n\nNaimi, Ashley I, Alan E Mishler, and Edward H Kennedy. 2023.\n“Challenges in Obtaining Valid Causal Effect Estimates with\nMachine Learning Algorithms.” American Journal of\nEpidemiology 192 (9): 1536–44.\n\n\nNaimi, Ashley I, Ya-Hui Yu, and Lisa M Bodnar. 2024.\n“Pseudo-Random Number Generator Influences on Average Treatment\nEffect Estimates Obtained with Machine Learning.”\nEpidemiology 35 (6): 779–86.\n\n\nOpacic, Aleksei, Lai Wei, and Xiang Zhou. 2025. “Disparity\nAnalysis: A Tale of Two Approaches.” Journal of the Royal\nStatistical Society Series A: Statistics in Society, qnaf008.\n\n\nRenson, Audrey, Lina Montoya, Dana E Goin, Iván Dı́az, and Rachael K\nRoss. 2025. “Pulling Back the Curtain: The Road from Statistical\nEstimand to Machine-Learning Based Estimator for Epidemiologists (No\nWizard Required).” arXiv Preprint arXiv:2502.05363.\n\n\nRose, Evan K. 2023. “A Constructivist Perspective on Empirical\nDiscrimination Research.” Journal of Economic Literature\n61 (3): 906–23.\n\n\nSchader, Lindsey, Weishan Song, Russell Kempker, and David Benkeser.\n2024. “Don’t Let Your Analysis Go to Seed: On the Impact of Random\nSeed on Machine Learning-Based Causal Inference.”\nEpidemiology 35 (6): 764–78.\n\n\nSchuler, Alejandro, and Mark van der Laan. 2024. “Introduction to\nModern Causal Inference.” preparation.\n\n\nStuart, Elizabeth A, Gary King, Kosuke Imai, and Daniel Ho. 2011.\n“MatchIt: Nonparametric Preprocessing for Parametric Causal\nInference.” Journal of Statistical Software.\n\n\nUrminsky, Oleg, Christian Hansen, and Victor Chernozhukov. 2019.\n“The Double-Lasso Method for Principled Variable\nSelection.”\n\n\nVafa, Keyon, Susan Athey, and David M Blei. 2024. “Estimating Wage\nDisparities Using Foundation Models.” arXiv Preprint\narXiv:2409.09894.\n\n\nVarian, Hal R. 2014. “Big Data: New Tricks for\nEconometrics.” Journal of Economic Perspectives 28 (2):\n3–28.\n\n\nWager, Stefan. 2024. “Causal Inference: A Statistical Learning\nApproach.” preparation.\n\n\nZhou, Xiang, and Aleksei Opacic. 2022. “Marginal Interventional\nEffects.” arXiv Preprint arXiv:2206.10717.\n\n\nZivich, Paul N. 2024. “Commentary: The Seedy Side of Causal Effect\nEstimation with Machine Learning.” Epidemiology 35 (6):\n787–90.\n\n\nZubizarreta, José R. 2015. “Stable Weights That Balance Covariates\nfor Estimation with Incomplete Outcome Data.” Journal of the\nAmerican Statistical Association 110 (511): 910–22.",
    "crumbs": [
      "Reference"
    ]
  }
]